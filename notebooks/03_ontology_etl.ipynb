{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏗️ 온톨로지 구축 ETL 파이프라인\n",
    "\n",
    "실무 데이터로 온톨로지를 자동으로 구축하는 방법을 배워봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 ETL이란?\n",
    "\n",
    "- **E**xtract (추출): 다양한 소스에서 데이터 수집\n",
    "- **T**ransform (변환): 데이터를 RAG에 적합한 형태로 가공\n",
    "- **L**oad (적재): 벡터 DB에 저장\n",
    "\n",
    "### 실무 시나리오\n",
    "회사의 금융 용어집, 규정 문서, FAQ를 RAG 시스템에 자동으로 적재"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from ontology_rag.core.rag_engine import RAGEngine\n",
    "from ontology_rag.embeddings.client import EmbeddingClient\n",
    "from ontology_rag.storage.vector_store import VectorStore\n",
    "\n",
    "load_dotenv()\n",
    "LLM_BASE_URL = os.getenv(\"LLM_BASE_URL\", \"http://localhost:11434\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"qwen2.5vl:72b\")\n",
    "\n",
    "# RAG 엔진 초기화\n",
    "embedder = EmbeddingClient(base_url=LLM_BASE_URL)\n",
    "store = VectorStore()\n",
    "rag = RAGEngine(\n",
    "    llm_base_url=LLM_BASE_URL,\n",
    "    llm_model=LLM_MODEL,\n",
    "    embedding_client=embedder,\n",
    "    vector_store=store,\n",
    ")\n",
    "\n",
    "print(\"✅ RAG 엔진 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Extract: 다양한 소스에서 데이터 추출\n",
    "\n",
    "### 1-1. JSON 파일에서 용어집 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금융 용어집 예시 데이터\n",
    "glossary_data = {\n",
    "    \"terms\": [\n",
    "        {\n",
    "            \"term\": \"온투금융\",\n",
    "            \"full_name\": \"온라인투자연계금융\",\n",
    "            \"definition\": \"온라인 플랫폼을 통해 투자자와 대출자를 직접 연결하는 금융 서비스\",\n",
    "            \"category\": \"금융상품\"\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"P2P 대출\",\n",
    "            \"full_name\": \"Peer-to-Peer Lending\",\n",
    "            \"definition\": \"개인 간 직접 대출을 중개하는 서비스로, 온투금융의 이전 명칭\",\n",
    "            \"category\": \"금융상품\"\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"신용등급\",\n",
    "            \"full_name\": \"Credit Rating\",\n",
    "            \"definition\": \"개인이나 기업의 신용도를 평가한 등급 (1~10등급)\",\n",
    "            \"category\": \"신용평가\"\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"연체율\",\n",
    "            \"full_name\": \"Delinquency Rate\",\n",
    "            \"definition\": \"대출금을 약정일에 상환하지 못한 비율\",\n",
    "            \"category\": \"리스크관리\"\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"중금리\",\n",
    "            \"full_name\": \"Mid-rate Interest\",\n",
    "            \"definition\": \"연 10~20% 수준의 금리로, 저금리와 고금리의 중간\",\n",
    "            \"category\": \"금리\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# JSON 파일로 저장\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with open(data_dir / \"glossary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(glossary_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 용어집 저장: {len(glossary_data['terms'])}개 용어\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. CSV 형태의 FAQ 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ 데이터\n",
    "faq_data = \"\"\"질문,답변,카테고리\n",
    "\"최소 투자금액은 얼마인가요?\",\"크플의 최소 투자금액은 10만원입니다.\",\"투자\"\n",
    "\"투자 수익은 언제 받나요?\",\"매월 원리금이 상환되며, 투자자 계좌로 자동 입금됩니다.\",\"투자\"\n",
    "\"대출 한도는 어떻게 결정되나요?\",\"AI 신용평가 시스템으로 개인별 신용도를 분석하여 최대 3,000만원까지 결정됩니다.\",\"대출\"\n",
    "\"중도 상환 수수료가 있나요?\",\"크플 대출은 중도상환 수수료가 없습니다.\",\"대출\"\n",
    "\"투자 원금 손실 가능성이 있나요?\",\"대출자의 연체나 부도 시 원금 손실 가능성이 있으며, 이는 투자 위험에 해당합니다.\",\"리스크\"\n",
    "\"\"\"\n",
    "\n",
    "with open(data_dir / \"faq.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(faq_data)\n",
    "\n",
    "print(\"✅ FAQ 데이터 저장\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Transform: 데이터 변환 및 구조화\n",
    "\n",
    "### 2-1. JSON 용어집 → 문서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_glossary(json_path):\n",
    "    \"\"\"용어집 JSON을 RAG 문서로 변환\"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for term_info in data[\"terms\"]:\n",
    "        # 구조화된 문서 생성\n",
    "        doc = f\"\"\"[용어] {term_info['term']}\n",
    "[영문/전체명] {term_info['full_name']}\n",
    "[정의] {term_info['definition']}\n",
    "[분류] {term_info['category']}\"\"\"\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "glossary_docs = transform_glossary(data_dir / \"glossary.json\")\n",
    "\n",
    "print(f\"✅ 용어집 변환 완료: {len(glossary_docs)}개 문서\")\n",
    "print(f\"\\n예시:\\n{glossary_docs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. CSV FAQ → 문서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def transform_faq(csv_path):\n",
    "    \"\"\"FAQ CSV를 RAG 문서로 변환\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            doc = f\"\"\"[FAQ - {row['카테고리']}]\n",
    "질문: {row['질문']}\n",
    "답변: {row['답변']}\"\"\"\n",
    "            documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "faq_docs = transform_faq(data_dir / \"faq.csv\")\n",
    "\n",
    "print(f\"✅ FAQ 변환 완료: {len(faq_docs)}개 문서\")\n",
    "print(f\"\\n예시:\\n{faq_docs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 텍스트 전처리 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"텍스트 정제\"\"\"\n",
    "    # 불필요한 공백 제거\n",
    "    text = \" \".join(text.split())\n",
    "    # 특수문자 정리 (필요시)\n",
    "    # text = re.sub(r'[^가-힣a-zA-Z0-9\\s\\[\\]\\-:,.]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 모든 문서 전처리\n",
    "all_docs = glossary_docs + faq_docs\n",
    "processed_docs = [preprocess_text(doc) for doc in all_docs]\n",
    "\n",
    "print(f\"✅ 전처리 완료: 총 {len(processed_docs)}개 문서\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Load: 벡터 DB에 적재\n",
    "\n",
    "### 3-1. 기존 데이터 초기화 (선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깨끗하게 시작하려면 주석 해제\n",
    "# store.clear()\n",
    "# print(\"🗑️ 기존 데이터 삭제\")\n",
    "\n",
    "print(f\"현재 저장된 문서: {store.count()}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 배치 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 적재\n",
    "rag.add_documents(processed_docs)\n",
    "\n",
    "print(f\"✅ 적재 완료!\")\n",
    "print(f\"총 문서 수: {store.count()}개\")\n",
    "print(f\"- 용어집: {len(glossary_docs)}개\")\n",
    "print(f\"- FAQ: {len(faq_docs)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 검증: 구축된 온톨로지 테스트\n",
    "\n",
    "### 4-1. 용어 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"온투금융이 뭐야?\",\n",
    "    \"중금리가 뭔가요?\",\n",
    "    \"P2P 대출 설명해줘\",\n",
    "]\n",
    "\n",
    "print(\"🧪 용어 검색 테스트\\n\" + \"=\"*80)\n",
    "\n",
    "for q in test_questions:\n",
    "    answer = rag.query(q, top_k=2)\n",
    "    print(f\"\\n질문: {q}\")\n",
    "    print(f\"답변: {answer}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. FAQ 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_questions = [\n",
    "    \"최소 투자금액 알려줘\",\n",
    "    \"대출 한도는 얼마야?\",\n",
    "    \"중도 상환 수수료 있어?\",\n",
    "]\n",
    "\n",
    "print(\"🧪 FAQ 검색 테스트\\n\" + \"=\"*80)\n",
    "\n",
    "for q in faq_questions:\n",
    "    answer = rag.query(q, top_k=2)\n",
    "    print(f\"\\n질문: {q}\")\n",
    "    print(f\"답변: {answer}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 고급: 자동 업데이트 파이프라인\n",
    "\n",
    "### 5-1. 증분 업데이트 (새 데이터만 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_update(new_data_path):\n",
    "    \"\"\"새로운 데이터만 추가\"\"\"\n",
    "    # 1. Extract\n",
    "    with open(new_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        new_data = json.load(f)\n",
    "    \n",
    "    # 2. Transform\n",
    "    new_docs = transform_glossary(new_data_path)\n",
    "    \n",
    "    # 3. Load\n",
    "    rag.add_documents(new_docs)\n",
    "    \n",
    "    return len(new_docs)\n",
    "\n",
    "# 예시: 새 용어 추가\n",
    "new_terms = {\n",
    "    \"terms\": [\n",
    "        {\n",
    "            \"term\": \"에어팩\",\n",
    "            \"full_name\": \"AIRPACK\",\n",
    "            \"definition\": \"PFCT의 AI 기반 신용 리스크 관리 B2B 솔루션\",\n",
    "            \"category\": \"제품\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(data_dir / \"new_terms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_terms, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "added = incremental_update(data_dir / \"new_terms.json\")\n",
    "print(f\"✅ {added}개 새 용어 추가\")\n",
    "print(f\"총 문서 수: {store.count()}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. 전체 ETL 파이프라인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_etl_pipeline(data_sources, clear_existing=False):\n",
    "    \"\"\"전체 ETL 파이프라인 실행\"\"\"\n",
    "    print(\"🚀 ETL 파이프라인 시작\\n\")\n",
    "    \n",
    "    # 0. 초기화 (선택)\n",
    "    if clear_existing:\n",
    "        store.clear()\n",
    "        print(\"🗑️ 기존 데이터 삭제\")\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    # 1. Extract & Transform\n",
    "    for source in data_sources:\n",
    "        source_type = source[\"type\"]\n",
    "        source_path = source[\"path\"]\n",
    "        \n",
    "        print(f\"📥 처리 중: {source_path}\")\n",
    "        \n",
    "        if source_type == \"glossary\":\n",
    "            docs = transform_glossary(source_path)\n",
    "        elif source_type == \"faq\":\n",
    "            docs = transform_faq(source_path)\n",
    "        else:\n",
    "            print(f\"⚠️ 알 수 없는 타입: {source_type}\")\n",
    "            continue\n",
    "        \n",
    "        all_documents.extend(docs)\n",
    "        print(f\"  ✓ {len(docs)}개 문서 변환\")\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    processed = [preprocess_text(doc) for doc in all_documents]\n",
    "    print(f\"\\n🔧 전처리 완료: {len(processed)}개 문서\")\n",
    "    \n",
    "    # 3. Load\n",
    "    rag.add_documents(processed)\n",
    "    print(f\"\\n✅ 적재 완료: 총 {store.count()}개 문서\")\n",
    "    \n",
    "    return store.count()\n",
    "\n",
    "# 사용 예시\n",
    "data_sources = [\n",
    "    {\"type\": \"glossary\", \"path\": data_dir / \"glossary.json\"},\n",
    "    {\"type\": \"faq\", \"path\": data_dir / \"faq.csv\"},\n",
    "]\n",
    "\n",
    "# total = run_etl_pipeline(data_sources, clear_existing=True)\n",
    "print(\"\\n💡 위 코드 주석을 해제하면 전체 파이프라인이 실행됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 모니터링 및 품질 관리\n",
    "\n",
    "### 6-1. 문서 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics():\n",
    "    \"\"\"문서 통계 확인\"\"\"\n",
    "    results = store.get_all()\n",
    "    docs = results['documents']\n",
    "    \n",
    "    total = len(docs)\n",
    "    avg_length = sum(len(doc) for doc in docs) / total if total > 0 else 0\n",
    "    \n",
    "    # 카테고리별 분류\n",
    "    categories = {}\n",
    "    for doc in docs:\n",
    "        if \"[용어]\" in doc:\n",
    "            categories[\"용어집\"] = categories.get(\"용어집\", 0) + 1\n",
    "        elif \"[FAQ\" in doc:\n",
    "            categories[\"FAQ\"] = categories.get(\"FAQ\", 0) + 1\n",
    "        else:\n",
    "            categories[\"기타\"] = categories.get(\"기타\", 0) + 1\n",
    "    \n",
    "    print(\"📊 문서 통계\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"총 문서 수: {total}개\")\n",
    "    print(f\"평균 문서 길이: {avg_length:.0f}자\")\n",
    "    print(f\"\\n카테고리별 분포:\")\n",
    "    for cat, count in categories.items():\n",
    "        print(f\"  - {cat}: {count}개 ({count/total*100:.1f}%)\")\n",
    "\n",
    "get_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. 검색 품질 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search_quality(test_cases):\n",
    "    \"\"\"검색 품질 평가\"\"\"\n",
    "    print(\"🎯 검색 품질 테스트\\n\" + \"=\"*80)\n",
    "    \n",
    "    for i, (question, expected_keyword) in enumerate(test_cases, 1):\n",
    "        answer = rag.query(question, top_k=2)\n",
    "        \n",
    "        # 기대 키워드가 답변에 포함되는지 확인\n",
    "        is_correct = expected_keyword.lower() in answer.lower()\n",
    "        status = \"✅\" if is_correct else \"❌\"\n",
    "        \n",
    "        print(f\"\\n{i}. {status} 질문: {question}\")\n",
    "        print(f\"   기대 키워드: {expected_keyword}\")\n",
    "        print(f\"   답변: {answer[:100]}...\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "# 테스트 케이스\n",
    "test_cases = [\n",
    "    (\"온투금융이 뭐야?\", \"온라인투자연계금융\"),\n",
    "    (\"최소 투자금액은?\", \"10만원\"),\n",
    "    (\"중금리 설명해줘\", \"10~20%\"),\n",
    "]\n",
    "\n",
    "test_search_quality(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 정리\n",
    "\n",
    "### ETL 파이프라인 구축 완료! 🎉\n",
    "\n",
    "**배운 내용:**\n",
    "1. ✅ 다양한 형식(JSON, CSV)에서 데이터 추출\n",
    "2. ✅ 구조화된 문서로 변환\n",
    "3. ✅ 벡터 DB에 효율적으로 적재\n",
    "4. ✅ 증분 업데이트 구현\n",
    "5. ✅ 품질 모니터링\n",
    "\n",
    "### 실무 적용 팁\n",
    "\n",
    "1. **자동화**: 크론잡이나 스케줄러로 주기적 실행\n",
    "2. **버전 관리**: 문서 변경 이력 추적\n",
    "3. **A/B 테스트**: 다른 청크 크기, 전처리 방법 비교\n",
    "4. **모니터링**: 검색 품질 지표 추적\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "- PDF, Word 문서 처리\n",
    "- 웹 크롤링 자동화\n",
    "- 실시간 업데이트 파이프라인\n",
    "- 멀티모달 데이터 (이미지, 표) 처리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ontology-rag)",
   "language": "python",
   "name": "ontology-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
